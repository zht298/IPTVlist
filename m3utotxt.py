# m3uæ ¼å¼è½¬txtï¼ŒæŒ‰m3uæ–‡ä»¶åå†™å‡ºtxtï¼Œå¯å¤„ç†å¤šä¸ªé“¾æ¥ï¼Œå¹¶åœ¨æ¯ä¸ªé“¾æ¥ä¸­æ·»åŠ ç»„åã€æ›´æ”¹ç»„åã€æ›´æ”¹é¢‘é“åç§°
import requests
from urllib.parse import urlparse, parse_qs, urlencode, urlunparse

def download_m3u_file(url):
    """ä»URLä¸‹è½½M3Uæ–‡ä»¶å†…å®¹ã€‚"""
    response = requests.get(url)
    response.raise_for_status()
    return response.text

def parse_m3u_content(m3u_content, default_group_name, rename_groups=None, rename_channel=None):
    """è§£æM3Uæ–‡ä»¶å†…å®¹ï¼Œå¹¶è¿”å›åŒ…å«é¢‘é“ä¿¡æ¯çš„æ’­æ”¾åˆ—è¡¨ã€‚"""
    lines = [line for line in m3u_content.splitlines() if line.strip()]  # åˆ é™¤æ‰€æœ‰ç©ºè¡Œ
    playlist = []
    current_group = default_group_name

    for line in lines:
        if line.startswith("#EXTINF"):
            try:
                if 'group-title="' in line:
                    parts = line.split('group-title="')
                    group_info = parts[1].split('"', 1)
                    group_name = group_info[0].strip()
                    channel_info = group_info[1].split(',', 1)
                    channel_name = channel_info[1].strip()
                else:
                    parts = line.split(',', 1)
                    channel_name = parts[1].strip()
                    group_name = current_group

                # å¦‚æœæŒ‡å®šäº†é‡å‘½ååˆ†ç»„ï¼Œåˆ™é‡å‘½ååˆ†ç»„
                if rename_groups and group_name in rename_groups:
                    group_name = rename_groups[group_name]

                # å¦‚æœæŒ‡å®šäº†é‡å‘½åé¢‘é“ï¼Œåˆ™é‡å‘½åé¢‘é“
                if rename_channel:
                    for old_name, new_name in rename_channel.items():
                        if old_name in channel_name:
                            channel_name = channel_name.replace(old_name, new_name)

            except IndexError:
                print(f"è·³è¿‡æ ¼å¼é”™è¯¯çš„è¡Œ: {line}")
                continue
        elif not line.startswith("#"):
            playlist.append([group_name, channel_name, line.strip()])

    return playlist

def save_playlist_to_txt(playlist, txt_filename):
    """å°†æ’­æ”¾åˆ—è¡¨ä¿å­˜åˆ°TXTæ–‡ä»¶ä¸­ã€‚"""
    with open(txt_filename, mode='w', encoding='utf-8') as file:
        current_group = None
        for item in playlist:
            group_name, channel_name, link = item
            if group_name != current_group:
                file.write(f"{group_name},#genre#\n")
                current_group = group_name
            file.write(f"{channel_name},{link}\n")

def process_m3u_urls(m3u_urls):
    """å¤„ç†ä¸€ç»„M3U URLï¼Œä¸‹è½½å¹¶è§£ææ¯ä¸ªM3Uæ–‡ä»¶ï¼Œå¹¶å°†ç»“æœä¿å­˜ä¸ºTXTæ–‡ä»¶ã€‚"""
    for url_info in m3u_urls:
        url = url_info['url']
        parsed_url = urlparse(url)
        query_params = parse_qs(parsed_url.query)
        default_group_name = query_params.get('group', [url_info.get('default_group', 'default')])[0]

        # å¦‚æœURLä¸­æœªæŒ‡å®šåˆ†ç»„ï¼Œåˆ™æ·»åŠ é»˜è®¤åˆ†ç»„
        if 'group' not in query_params:
            query_params['group'] = [url_info.get('default_group', 'default')]
            query_string = urlencode(query_params, doseq=True)
            parsed_url = parsed_url._replace(query=query_string)
            url = urlunparse(parsed_url)

        # ä¸‹è½½ M3U æ–‡ä»¶å†…å®¹ï¼ˆå¿½ç•¥ URL ä¸­çš„æŸ¥è¯¢å‚æ•°ï¼‰
        m3u_content = download_m3u_file(url.split('?')[0])
        m3u_filename = parsed_url.path.split("/")[-1]
        txt_filename = m3u_filename.replace('.m3u', '.txt')

        # åˆå¹¶é‡å‘½åé¢‘é“çš„å­—å…¸
        rename_channel = url_info.get('rename_channel', {})
        rename_channel.update(url_info.get('rename_channel1', {}))
        rename_channel.update(url_info.get('rename_channel2', {}))

        playlist = parse_m3u_content(
            m3u_content, 
            default_group_name, 
            rename_groups=url_info.get('rename_groups'),
            rename_channel=rename_channel
        )
        save_playlist_to_txt(playlist, txt_filename)

def main():
    """ä¸»å‡½æ•°ï¼Œå®šä¹‰M3U URLå¹¶å¤„ç†å®ƒä»¬ã€‚"""
    m3u_urls = [
        {
            "url": "https://raw.githubusercontent.com/zht298/IPTVlist/main/playlist.m3u",
            # "rename_groups": {"ğŸ’å¤®è§†é¢‘é“": "å¤®è§†"},
            # "rename_channel": {"CCTV1 ç»¼åˆ": " ç»¼åˆ"},
        },
       #  {
       #      "url": "https://raw.githubusercontent.com/zht298/IPTVlist/main/playlist.m3u",
       #      "rename_groups": {"ğŸ’å¤®è§†é¢‘é“": "å¤®è§†"},
       #      "rename_channel": {"CCTV1 ç»¼åˆ": " ç»¼åˆ"},
       #  },
        {
            "url": "http://adultiptv.net/chs.m3u",
            "default_group": "æˆäººç›´æ’­_9",
            "rename_groups": {"XXX": "æˆäººç‚¹æ’­_9"},
            "rename_channel1": {"MyCamTV ": ""},
            "rename_channel2": {"AdultIPTV.net ": ""},
        },
        # æ·»åŠ æ›´å¤šçš„é“¾æ¥ï¼Œå¹¶åœ¨URLä¸­æŒ‡å®šè‡ªå®šä¹‰é¢‘é“åˆ†ç»„åç§°
    ]
    process_m3u_urls(m3u_urls)

if __name__ == "__main__":
    main()
import requests
import re
from collections import defaultdict
import subprocess
import warnings
import time

# ç¦ç”¨æœªéªŒè¯çš„HTTPSè¯·æ±‚è­¦å‘Š
warnings.filterwarnings('ignore', message='Unverified HTTPS request')

def download_txt_file(url, filename):
    """ä»URLä¸‹è½½TXTæ–‡ä»¶å¹¶ä¿å­˜åœ¨æœ¬åœ°ã€‚"""
    retries = 3
    for attempt in range(retries):
        try:
            print(f"æ­£åœ¨å°è¯•ä¸‹è½½æ–‡ä»¶: {url} (å°è¯•æ¬¡æ•°: {attempt + 1})")
            response = requests.get(url, verify=False)  # ç»•è¿‡ SSL éªŒè¯
            response.raise_for_status()
            with open(filename, 'wb') as file:
                file.write(response.content)
            print(f"æˆåŠŸä¸‹è½½æ–‡ä»¶: {url}")
            return
        except requests.exceptions.SSLError as e:
            print(f"SSL é”™è¯¯ï¼š{e}")
        except requests.exceptions.RequestException as e:
            print(f"è¯·æ±‚é”™è¯¯ï¼š{e}")
        if attempt < retries - 1:
            print("ç­‰å¾…3ç§’åé‡è¯•...")
            time.sleep(3)
    print(f"æ— æ³•ä¸‹è½½æ–‡ä»¶ï¼š{url}")

def merge_txt_files(file_list, output_filename, max_channels_per_name):
    """å°†å¤šä¸ªTXTæ–‡ä»¶åˆå¹¶æˆä¸€ä¸ªæ–‡ä»¶ï¼Œå¹¶è¿‡æ»¤æ‰IPv6åœ°å€åŠæŒ‰æŒ‡å®šæ•°é‡ä¿ç•™æ¯ä¸ªé¢‘é“åç§°çš„é¡¹ã€‚"""
    group_dict = defaultdict(lambda: defaultdict(list))
    ipv6_pattern = re.compile(r'([a-f0-9:]+:+)+[a-f0-9]+')

    for filename, groups in file_list:
        print(f"æ­£åœ¨å¤„ç†æ–‡ä»¶: {filename}")
        with open(filename, 'r', encoding='utf-8', errors='ignore') as infile:
            current_group = None
            for line in infile:
                if line.startswith("#") or not line.strip():
                    continue
                parts = line.split(',')
                if len(parts) == 2 and parts[1].startswith('#genre#'):
                    current_group = parts[0].strip()
                    print(f"æ‰¾åˆ°åˆ†ç»„: {current_group}")
                elif current_group and len(parts) == 2:
                    channel_name, link = parts[0].strip(), parts[1].strip()
                    if not ipv6_pattern.search(link) and (groups is None or current_group.lower() in [g.lower() for g in groups]):  # è¿‡æ»¤æ‰IPv6é“¾æ¥å’ŒéæŒ‡å®šåˆ†ç»„
                        group_dict[current_group][channel_name].append(link)

    print("åˆå¹¶åçš„åˆ†ç»„åç§°ï¼š")
    for group in group_dict.keys():
        print(f"åˆå¹¶åˆ†ç»„: {group}")

    with open(output_filename, 'w', encoding='utf-8') as outfile:
        for group, channels in group_dict.items():
            outfile.write(f"{group},#genre#\n")
            print(f"å†™å…¥åˆ†ç»„: {group}")  # æ‰“å°å†™å…¥åˆ°æ–‡ä»¶ä¸­çš„åˆ†ç»„åç§°
            for channel_name, links in channels.items():
                for link in links[:max_channels_per_name]:
                    outfile.write(f"{channel_name},{link}\n")

def git_add_files(files, user_name, user_email):
    """å°†æ–‡ä»¶æ·»åŠ åˆ°Gitç‰ˆæœ¬æ§åˆ¶ä¸­ã€‚"""
    # è®¾ç½®ç”¨æˆ·ä¿¡æ¯
    subprocess.run(["git", "config", "user.name", user_name])
    subprocess.run(["git", "config", "user.email", user_email])
    
    for file in files:
        subprocess.run(["git", "add", file])
    subprocess.run(["git", "commit", "-m", "Add new downloaded files"])
    subprocess.run(["git", "push"])

def main():
    txt_urls_with_groups = [
        # ("https://raw.githubusercontent.com/yuanzl77/IPTV/main/live.txt", ["å¤®è§†é¢‘é“", "å«è§†é¢‘é“","å½±è§†é¢‘é“"]),
        # å‡ºå¤„ æœˆå…‰å®ç›’æŠ“å–ç›´æ’­
        ("https://ygbh.site/bh.txt", ["ğŸ’ä¸­å›½ç§»åŠ¨ITVğŸ‘‰ç§»åŠ¨","ğŸ’æ±•å¤´å¤®å«ğŸ‘‰å¹¿ä¸œ","ç„¦ç‚¹é¦™æ¸¯"]),  # ä¿ç•™æ‰€æœ‰åˆ†ç»„
        # å°è‹¹æœï¼Œèœ—ç‰›çº¿è·¯[æµ‹è¯•2]
        # ("http://wp.wadg.pro/down.php/d7b52d125998d00e2d2339bac6abd2b5.txt", ["å¤®è§†é¢‘é“â‘ ", "ğŸ’å¤®è§†é¢‘é“", "å«è§†é¢‘é“â‘ ", "ğŸ“¡å«è§†é¢‘é“","éŸ©å›½é¢‘é“"]),      
        # ("https://raw.githubusercontent.com/zht298/IPTVlist/main/dalian.txt", None),  # ä¿ç•™æ‰€æœ‰åˆ†ç»„  å¤§è¿å°
        # å‡ºå¤„ å°é¹¦é¹‰ç­‰å¤šå¤„è·å– 
        # ("https://raw.githubusercontent.com/zht298/IPTVlist/main/JJdoudizhu.txt", None),  # ä¿ç•™æ‰€æœ‰åˆ†ç»„  JJæ–—åœ°ä¸»
        # å‡ºå¤„ https://adultiptv.net/â†’http://adultiptv.net/chs.m3u
        # ("https://raw.githubusercontent.com/zht298/IPTVlist/main/chs.txt",None),  # ä¿ç•™æ‰€æœ‰åˆ†ç»„
        # æ·»åŠ æ›´å¤šçš„é“¾æ¥å’Œå¯¹åº”çš„åˆ†ç»„
    ]
    local_filenames_with_groups = []

    # æ­¥éª¤1ï¼šä¸‹è½½TXTæ–‡ä»¶
    for i, (url, groups) in enumerate(txt_urls_with_groups, start=1):
        local_filename = f"file{i}.txt"
        download_txt_file(url, local_filename)
        local_filenames_with_groups.append((local_filename, groups))

    # æ­¥éª¤2ï¼šåˆå¹¶TXTæ–‡ä»¶å¹¶è¿‡æ»¤
    output_filename = "merged_output.txt"
    max_channels_per_name = 10  # è®¾ç½®æ¯ä¸ªé¢‘é“åç§°æœ€å¤šä¿ç•™çš„é¡¹æ•°é‡
    merge_txt_files(local_filenames_with_groups, output_filename, max_channels_per_name)

    # æ­¥éª¤3ï¼šæ·»åŠ æ–‡ä»¶åˆ°Gitç‰ˆæœ¬æ§åˆ¶ä¸­
    user_name = "zht298"
    user_email = "zht19886@gmail.com"
    git_add_files([f"file{i}.txt" for i in range(1, len(txt_urls_with_groups) + 1)] + ["merged_output.txt"], user_name, user_email)

if __name__ == "__main__":
    main()
